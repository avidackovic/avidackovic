{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGJstc2F7IhW"
      },
      "source": [
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/6/63/ETH_Z%C3%BCrich_wordmark.svg\" width=\"200\" height=\"200\" align=\"left\">\n",
        "<br />\n",
        "<br /><br />\n",
        "<div align=\"right\"> <b/> FS 2022\n",
        "<br />\n",
        "    \n",
        "## <div align=\"center\"> Project & Seminars: Python for Science & Machine Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WrnfsDv7jnu"
      },
      "source": [
        "---\n",
        "\n",
        "# <div align=\"center\"> Exercise 7th week: Machine Learning with PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xeDUC-F8i2E"
      },
      "source": [
        "In this exercise we will do basic image classification on the popular CIFAR-10 dataset using the PyTorch framework."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAXuwClu9MqQ"
      },
      "source": [
        "## 1. Load PyTorch Packages and Dataset\n",
        "First we load PyTorch packages and some helper libraries that you already know. `torch` is the core package of PyTorch. `torchvision` is PyTorch's computer vision package and contains some popular datasets, models and image transformations. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CX4-QhK56yJ7"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torch'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# PyTorch packages\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# helper libraries\u001b[39;00m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
          ]
        }
      ],
      "source": [
        "# PyTorch packages\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "# helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-y69jlw74kT"
      },
      "source": [
        "Now we are ready to load and play with the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTW9P4EpEd2n"
      },
      "outputs": [],
      "source": [
        "# the training set is used to train the model\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True)\n",
        "# the test set is used to test the accuracy of the model\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qVbizm4XyMA"
      },
      "source": [
        "Now you can see the downloaded dataset in the data folder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQEnTeLhEeap"
      },
      "source": [
        "## 2. Explore the Data\n",
        "\n",
        "It is useful to have a basic familiarity with the data structure. Let's explore the format of the dataset before training the model. We can find the official website for CIFAR-10 via search engine. There, we see some basic information about it, such as the classes, number of images and their resolution. Let's verify this information.\n",
        "\n",
        "**Exercise 2.1: Number of images**  \n",
        "Print the length of both train and test set. What is the total number of images?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJiNGXRSEemy"
      },
      "outputs": [],
      "source": [
        "# INSERT CODE HERE\n",
        "test12"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZvPqV8Xy-tl"
      },
      "source": [
        "Now try to print their shapes by using dot notation: `.data.shape`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1lm_caSQy_Af"
      },
      "outputs": [],
      "source": [
        "# INSERT CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ib4h2O7kEevG"
      },
      "source": [
        "**Exercise 2.2: Format**  \n",
        "Print the first element of each set via indexing like a list. Then print the type for one element of your choice using `type()`. What do you notice about the format?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39oEzrn-Ee0r"
      },
      "outputs": [],
      "source": [
        "# INSERT CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CKkKfFoWh_A"
      },
      "source": [
        "**Exercise 2.3: Labels**  \n",
        "Let's obtain the labels for the trainset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6qmdpGUWiJL"
      },
      "outputs": [],
      "source": [
        "labels = trainset.targets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0nQGyTHcJ-A"
      },
      "source": [
        "`labels` is a list. Use indexing to print the first 10."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0z4APFL1cJWJ"
      },
      "outputs": [],
      "source": [
        "# INSERT CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdG7j4CdcdJ6"
      },
      "source": [
        "As you can see, the labels are integers. Let's find out what each of them means."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_orNbLBcda4"
      },
      "outputs": [],
      "source": [
        "trainset.class_to_idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GejWTeg_biAw"
      },
      "source": [
        "As we have seen above, the dataset elements are tuples containing (PIL image, label). PIL images can be displayed directly by indexing them like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kkFCy-vbfso"
      },
      "outputs": [],
      "source": [
        "trainset[42][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPyO6gjbWiXz"
      },
      "source": [
        "Now combine your new knowledge to display the first cat in the training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQqBruvHWieQ"
      },
      "outputs": [],
      "source": [
        "# INSERT CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaYh_pR8Wik-"
      },
      "source": [
        "**Exercise 2.4: PIL to numpy**  \n",
        "Convert the cat image to a numpy array and print its shape and data type using dot notation: `.shape` and `.dtype`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VPYz73mnWiq_"
      },
      "outputs": [],
      "source": [
        "cat = # INSERT CODE HERE\n",
        "# INSERT CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIB3rSRiWix1"
      },
      "source": [
        "**Exercise 2.5: Plot the image**  \n",
        "From the previous exercise we can see that the image resolution is 32x32 with 3 color channels. Each pixel is represented as three 8-bit integers with values from 0 to 255 for its red, green and blue values. Let's have a look at the array itself to verify this. Execute the following line to see a part of it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRKxlR-AWi4b"
      },
      "outputs": [],
      "source": [
        "cat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SNS025kEe62"
      },
      "source": [
        "Now plot the image using pyplot's `imshow` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjfev5rHfXSC"
      },
      "outputs": [],
      "source": [
        "# INSERT CODE HERE\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoUPquzgs0mb"
      },
      "source": [
        "**Exercise 2.6 (Optional): Grid plot**  \n",
        "Let's use a for loop to plot the first 25 images of the training set in a 5x5 grid. Use pyplot's `subplot` function for this and don't forget to convert the PIL images to numpy arrays. Try to keep it simple, only 2 lines of code are missing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mypeSbq5s01i"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    # INSERT CODE HERE\n",
        "    \n",
        "    \n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfecb524uINf"
      },
      "source": [
        "Can you classify them all by eye? The difficulty varies a lot. Trying some of the harder examples makes me appreciate how well neural nets work."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_74VyptfXcO"
      },
      "source": [
        "## 3. Dataloaders  \n",
        "In this section we prepare the dataloaders used for training the model. Dataloaders are an essential part and handle the data for us.  \n",
        "  \n",
        "For both PyTorch and TensorFlow we usually work with tensors. They have a lot in common with numpy arrays. Torch tensors and numpy arrays can easily be converted from one to the other.  \n",
        "  \n",
        "Tensors can be seen simply as generalization of vectors and matrices. While vectors are 1D-grids of numbers and matrices are 2D-grids, tensors are grids with arbitrary number of dimensions. Vectors are first order tensors and matrices are second order tensors.  \n",
        "  \n",
        "Images are usually represented as 4th order tensors: (batch size, number of color channels, height, width). The batch size will become relevant later when we train a model. The other 3 values you are already familiar with from previous exercises with numpy.  \n",
        "  \n",
        "**Exercise 3.1: Tensor format**  \n",
        "Let's transform the images to tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Il1AdbhkfXmP"
      },
      "outputs": [],
      "source": [
        "# we do this so we have to type less\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# define the transformation\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "# reload the dataset with the transformation applied\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3Y9xjqZfXsH"
      },
      "source": [
        "Print the first element of the training set and compare it with the previous exercise. Then print the tensor's shape and datatype using `.shape` and `.dtype` like with the numpy array in exercise 2.4. What do you notice?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xwzr6NzcfXzO"
      },
      "outputs": [],
      "source": [
        "# INSERT CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfdDsAzXfX4Y"
      },
      "source": [
        "Indeed, conversion to tensor also changes the variables to floats in the range [0, 1] and moves the number of channels in front of the resolution. This is also described in the official documentation:  \n",
        "https://pytorch.org/vision/stable/generated/torchvision.transforms.ToTensor.html  \n",
        "  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQ12O3ukqdiQ"
      },
      "source": [
        "**Exercise 3.2: Normalization**  \n",
        "Depending on application, the input to neural networks is often normalized so that the feature ranges are similar. Normalization is the following transformation: `out = (in - mean)/standard deviation`. A common choice for normalization is to simply use means and standard deviations 0.5 for all channels like this.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g75Q6PdMqdtv"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) # (mean), (std)\n",
        "\n",
        "# let's test the normalization\n",
        "transform(np.array([[[0,0.5,1]]],dtype='float32'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LU8j_Y5c5w21"
      },
      "source": [
        "Maybe we can do better. Let's calculate CIFAR-10's mean and std."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-0uun_gqd6T"
      },
      "outputs": [],
      "source": [
        "print((trainset.data.mean(axis=(0,1,2))/255).round(4))\n",
        "print((trainset.data.std(axis=(0,1,2))/255).round(4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gg6l6KcW6Ifd"
      },
      "source": [
        "Use the result above to write your own transformation below with modified normalization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kCsZb2s6Hzr"
      },
      "outputs": [],
      "source": [
        "# define the transformation\n",
        "transform = # INSERT CODE HERE\n",
        "\n",
        "# reload the dataset with the transformation applied\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usJ2pRyuqdz7"
      },
      "source": [
        "To train neural networks we use dataloaders, which automatically shuffle the images, apply the transformation and serve them in batches. Note that we only shuffle for the training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gD1ObmeFAkQX"
      },
      "outputs": [],
      "source": [
        "# the batch size represents how many images we use per training iteration\n",
        "batch_size = 10\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQD0JRY4Akt8"
      },
      "source": [
        "## 4. Model\n",
        "\n",
        "It is time for us to define our model. For this, we choose the famous LeNet-5 modified to CIFAR-10. For now, you don't need to understand the details. We will have a closer look during the next lecture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nmVRQBBYAlde"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class LeNet(nn.Module):\n",
        "    # here we define the layers that we will use\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.flat = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10) # 10 outputs\n",
        "    # here we define the forward pass\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.flat(x)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rc9CP3IVSNar"
      },
      "source": [
        "## 5. Learning Rate Range Test\n",
        "We do not yet know what learning rate we should choose for training. The ideal learning rate can vary by many orders of magnitude depending on a lot of different factors from model, data, optimizer, batch size and more. Randomly guessing is very inefficient and time consuming. Therefore, we will use a learning rate range test to narrow it down.  \n",
        "  \n",
        "Since our model is very small and GPU availability on Colab is limited, we will stick to CPU for now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSR0IvegUGsM"
      },
      "outputs": [],
      "source": [
        "# we create our neural network\n",
        "net = LeNet()\n",
        "\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "# this is our loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# this is our optimizer: stochastic gradient descent with momentum\n",
        "# notice we set our starting learning rate to 1e-4, you can change it\n",
        "optimizer = optim.SGD(net.parameters(), lr=1e-4, momentum=0.9)\n",
        "\n",
        "# collect [learning rate, loss] for every training iteration\n",
        "metrics = [[],[]]\n",
        "\n",
        "# we use a maximum of  2 epochs to prevent it from taking too long\n",
        "for epoch in range(2):\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs from data, which is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward pass\n",
        "        outputs = net(inputs)\n",
        "        # calculate loss\n",
        "        loss = criterion(outputs, labels)\n",
        "        # backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print our progress every 1000 batches\n",
        "        if i % 1000 == 999:\n",
        "            print(f'Epoch {epoch+1} batch {i+1} complete.')\n",
        "        \n",
        "        # access our learning rate hyperparameter\n",
        "        for pg in optimizer.param_groups:\n",
        "            # update metrics\n",
        "            metrics[0].extend([pg['lr']])\n",
        "            metrics[1].extend([loss.item()])\n",
        "            # exponentially increase learning rate\n",
        "            pg['lr'] *= 1.001 # you can change this!\n",
        "        # early abort if learning rate gets too big\n",
        "        if metrics[0][-1] > 0.1: # you can change this!\n",
        "            break \n",
        "    else:\n",
        "        continue\n",
        "    print('Finished early!')\n",
        "    break\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N33r27heft8k"
      },
      "source": [
        "**Exercise 5.1: Plot metrics**  \n",
        "It's time to plot the metrics with x-axis as learning rate and y-axis as loss. We want to use a `semilogx` plot because the learning rate is increasing exponentially. Since the data is very noisy, we also want to plot a moving average."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45Mxc3YZUuM1"
      },
      "outputs": [],
      "source": [
        "cumsum = np.cumsum(np.insert(np.array(metrics[1]), 0, 0))\n",
        "width = 20\n",
        "moving_average = (cumsum[width:] - cumsum[:-width])/width\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "# INSERT CODE HERE\n",
        "\n",
        "\n",
        "plt.ylim(0,4) # feel free to modify this as needed\n",
        "plt.xlabel('Learning Rate')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHx5KuEIggGd"
      },
      "source": [
        "Even though the data is noisy, it should give us some key information. We see at which learning rate the loss starts to decrease and at which point it stops decreasing and then increases again, perhaps even diverges. A learning rate in the middle of the downward slope might be a good starting point."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJcNdYtNAlun"
      },
      "source": [
        "## 6. Training\n",
        "\n",
        "It is time to train our neural network. This should take 3-4 minutes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DGaT9CKRdrHv"
      },
      "outputs": [],
      "source": [
        "net = LeNet()\n",
        "\n",
        "import time\n",
        "import torch.optim as optim\n",
        "\n",
        "# this is our loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# this is our optimizer: stochastic gradient descent with momentum\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.002, momentum=0.9)\n",
        "\n",
        "start_time = time.time()\n",
        "for epoch in range(5):  # loop over the dataset every epoch\n",
        "    # to collect training statistics\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs from data, which is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward pass\n",
        "        outputs = net(inputs)\n",
        "        # calculate loss\n",
        "        loss = criterion(outputs, labels)\n",
        "        # backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # update training statistics\n",
        "        running_loss += loss.item()\n",
        "        predicted = torch.argmax(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    # print training statistics after every epoch\n",
        "    print(f'Epoch {epoch+1} complete. Loss: {running_loss / 5000:.3f}, '+\n",
        "          f'training accuracy: {100 * correct / total}')\n",
        "\n",
        "\n",
        "print('Finished training in', round(time.time()-start_time,3),'seconds')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-p1AClDzh76_"
      },
      "source": [
        "**Exercise 6.1: Test accuracy**  \n",
        "It is time to test our true accuracy on the test set. Finish the code below. 5 lines of code are missing. Each can be copied from the training loop above.  \n",
        "*Tip: we only need the forward pass.*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "udcwanG-eFNh"
      },
      "outputs": [],
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "# since we are not training, we don't want to evaluate the gradients\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        # INSERT CODE HERE\n",
        "        \n",
        "\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total}%')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcQJxigZrQgU"
      },
      "source": [
        "**Exercise 6.2: Logits and softmax**  \n",
        "Let's look at a single output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QObG1YzCrWoU"
      },
      "outputs": [],
      "source": [
        "images, labels = iter(testloader).next()\n",
        "with torch.no_grad(): outputs = net(images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDx3GjqgrWwx"
      },
      "source": [
        "`outputs` now contains the outputs for the first test batch. Print the output for the first image only."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H35BuEgwrW5q"
      },
      "outputs": [],
      "source": [
        "# INSERT CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_FmFaHuvLAd"
      },
      "source": [
        "These are called logits. By themselves, they are not very meaningful for humans. The softmax function can be used to turn the logits into pseudo probabilities by rescaling them to the range [0, 1] with a sum of 1. Use torch's softmax functional to turn the outputs into probabilities and print the probabilities for the first image.  \n",
        "https://pytorch.org/docs/stable/generated/torch.nn.functional.softmax.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZsrBXQKivpNJ"
      },
      "outputs": [],
      "source": [
        "# INSERT CODE HERE\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "exercise07.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
